{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### <center>Data Munging with Apache Spark: Using Apache Parquet, Pivot table and doing some viz, _using R_.</center>\n",
    "<center>@geraudster</center>\n",
    "\n",
    "![TDS Logo](http://photos1.meetupstatic.com/photos/event/8/a/5/2/global_434255410.jpeg)\n",
    "\n",
    "\n",
    "Apache Parquet is designed to bring efficient columnar storage to Hadoop and has the following characteristics:\n",
    "\n",
    "* Self-describing\n",
    "* Columnar format\n",
    "* Efficiently encode nested structures and sparsely populated data based on the Google Dremel definition/repetition levels\n",
    "* Language-independent\n",
    "\n",
    "Parquet arranges data in columns, putting related values in close proximity to each other to optimize query performance, minimize I/O, and facilitate compression. Parquet detects and encodes the same or similar data using a technique that conserves resources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will initialize the Spark context (sc) by setting some environment variables and loading the _SparkR_ package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Attaching package: ‘SparkR’\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    cov, filter, lag, na.omit, predict, sd, var\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    colnames, colnames<-, endsWith, intersect, rank, rbind, sample,\n",
      "    startsWith, subset, summary, table, transform\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching java with spark-submit command /opt/spark/spark-1.6.1-bin-hadoop2.6/bin/spark-submit   \"--packages\" \"com.databricks:spark-csv_2.11:1.3.0\" \"sparkr-shell\" /tmp/RtmpbQN1Gw/backend_port3245fbb49b0 \n"
     ]
    }
   ],
   "source": [
    "# Set this to where Spark is installed\n",
    "Sys.setenv(SPARK_HOME=\"/opt/spark/spark-1.6.1-bin-hadoop2.6\")\n",
    "Sys.setenv('SPARKR_SUBMIT_ARGS'='\"--packages\" \"com.databricks:spark-csv_2.11:1.3.0\" \"sparkr-shell\"')\n",
    "\n",
    "# This line loads SparkR from the installed directory\n",
    ".libPaths(c(file.path(Sys.getenv(\"SPARK_HOME\"), \"R\", \"lib\"), .libPaths()))\n",
    "\n",
    "# Load the SparkR library\n",
    "library(SparkR)\n",
    "sc <- sparkR.init(master=\"local[*]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Bike and Weather data in Parquet format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqlContext <- sparkRSQL.init(sc)\n",
    "bikes_weather <- read.parquet(sqlContext, 'data/bike_sharing/bike_weather.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- datetime: timestamp (nullable = true)\n",
      " |-- season: string (nullable = true)\n",
      " |-- holiday: boolean (nullable = true)\n",
      " |-- workingday: boolean (nullable = true)\n",
      " |-- weather: string (nullable = true)\n",
      " |-- temp: double (nullable = true)\n",
      " |-- atemp: double (nullable = true)\n",
      " |-- humidity: double (nullable = true)\n",
      " |-- windspeed: double (nullable = true)\n",
      " |-- casual: integer (nullable = true)\n",
      " |-- registered: integer (nullable = true)\n",
      " |-- count: integer (nullable = true)\n"
     ]
    }
   ],
   "source": [
    "printSchema(bikes_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>datetime</th><th scope=col>season</th><th scope=col>holiday</th><th scope=col>workingday</th><th scope=col>weather</th><th scope=col>temp</th><th scope=col>atemp</th><th scope=col>humidity</th><th scope=col>windspeed</th><th scope=col>casual</th><th scope=col>registered</th><th scope=col>count</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>2011-01-15 19:00:00                                         </td><td>springer                                                    </td><td>FALSE                                                       </td><td>FALSE                                                       </td><td>Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist</td><td>13.12                                                       </td><td>15.15                                                       </td><td>39                                                          </td><td>16.998                                                      </td><td>14                                                          </td><td>60                                                          </td><td>74                                                          </td></tr>\n",
       "\t<tr><th scope=row>2</th><td>2011-01-23 18:00:00                            </td><td>springer                                       </td><td>FALSE                                          </td><td>FALSE                                          </td><td>Clear, Few clouds, Partly cloudy, Partly cloudy</td><td>4.92                                           </td><td>6.06                                           </td><td>30                                             </td><td>16.998                                         </td><td>5                                              </td><td>44                                             </td><td>49                                             </td></tr>\n",
       "\t<tr><th scope=row>3</th><td>2011-01-24 04:00:00                            </td><td>springer                                       </td><td>FALSE                                          </td><td>TRUE                                           </td><td>Clear, Few clouds, Partly cloudy, Partly cloudy</td><td>0.82                                           </td><td>3.03                                           </td><td>48                                             </td><td>8.998                                          </td><td>0                                              </td><td>1                                              </td><td>1                                              </td></tr>\n",
       "\t<tr><th scope=row>4</th><td>2011-02-13 11:00:00                            </td><td>springer                                       </td><td>FALSE                                          </td><td>FALSE                                          </td><td>Clear, Few clouds, Partly cloudy, Partly cloudy</td><td>13.12                                          </td><td>14.395                                         </td><td>39                                             </td><td>30.003                                         </td><td>26                                             </td><td>86                                             </td><td>112                                            </td></tr>\n",
       "\t<tr><th scope=row>5</th><td>2011-03-04 22:00:00                            </td><td>springer                                       </td><td>FALSE                                          </td><td>TRUE                                           </td><td>Clear, Few clouds, Partly cloudy, Partly cloudy</td><td>12.3                                           </td><td>14.395                                         </td><td>70                                             </td><td>12.998                                         </td><td>4                                              </td><td>40                                             </td><td>44                                             </td></tr>\n",
       "\t<tr><th scope=row>6</th><td>2011-03-20 10:00:00                                         </td><td>springer                                                    </td><td>FALSE                                                       </td><td>FALSE                                                       </td><td>Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist</td><td>13.12                                                       </td><td>17.425                                                      </td><td>45                                                          </td><td>0                                                           </td><td>55                                                          </td><td>81                                                          </td><td>136                                                         </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllllllll}\n",
       "  & datetime & season & holiday & workingday & weather & temp & atemp & humidity & windspeed & casual & registered & count\\\\\n",
       "\\hline\n",
       "\t1 & 2011-01-15 19:00:00                                          & springer                                                     & FALSE                                                        & FALSE                                                        & Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist & 13.12                                                        & 15.15                                                        & 39                                                           & 16.998                                                       & 14                                                           & 60                                                           & 74                                                          \\\\\n",
       "\t2 & 2011-01-23 18:00:00                             & springer                                        & FALSE                                           & FALSE                                           & Clear, Few clouds, Partly cloudy, Partly cloudy & 4.92                                            & 6.06                                            & 30                                              & 16.998                                          & 5                                               & 44                                              & 49                                             \\\\\n",
       "\t3 & 2011-01-24 04:00:00                             & springer                                        & FALSE                                           & TRUE                                            & Clear, Few clouds, Partly cloudy, Partly cloudy & 0.82                                            & 3.03                                            & 48                                              & 8.998                                           & 0                                               & 1                                               & 1                                              \\\\\n",
       "\t4 & 2011-02-13 11:00:00                             & springer                                        & FALSE                                           & FALSE                                           & Clear, Few clouds, Partly cloudy, Partly cloudy & 13.12                                           & 14.395                                          & 39                                              & 30.003                                          & 26                                              & 86                                              & 112                                            \\\\\n",
       "\t5 & 2011-03-04 22:00:00                             & springer                                        & FALSE                                           & TRUE                                            & Clear, Few clouds, Partly cloudy, Partly cloudy & 12.3                                            & 14.395                                          & 70                                              & 12.998                                          & 4                                               & 40                                              & 44                                             \\\\\n",
       "\t6 & 2011-03-20 10:00:00                                          & springer                                                     & FALSE                                                        & FALSE                                                        & Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist & 13.12                                                        & 17.425                                                       & 45                                                           & 0                                                            & 55                                                           & 81                                                           & 136                                                         \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "             datetime   season holiday workingday\n",
       "1 2011-01-15 19:00:00 springer   FALSE      FALSE\n",
       "2 2011-01-23 18:00:00 springer   FALSE      FALSE\n",
       "3 2011-01-24 04:00:00 springer   FALSE       TRUE\n",
       "4 2011-02-13 11:00:00 springer   FALSE      FALSE\n",
       "5 2011-03-04 22:00:00 springer   FALSE       TRUE\n",
       "6 2011-03-20 10:00:00 springer   FALSE      FALSE\n",
       "                                                       weather  temp  atemp\n",
       "1 Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist 13.12 15.150\n",
       "2              Clear, Few clouds, Partly cloudy, Partly cloudy  4.92  6.060\n",
       "3              Clear, Few clouds, Partly cloudy, Partly cloudy  0.82  3.030\n",
       "4              Clear, Few clouds, Partly cloudy, Partly cloudy 13.12 14.395\n",
       "5              Clear, Few clouds, Partly cloudy, Partly cloudy 12.30 14.395\n",
       "6 Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist 13.12 17.425\n",
       "  humidity windspeed casual registered count\n",
       "1       39    16.998     14         60    74\n",
       "2       30    16.998      5         44    49\n",
       "3       48     8.998      0          1     1\n",
       "4       39    30.003     26         86   112\n",
       "5       70    12.998      4         40    44\n",
       "6       45     0.000     55         81   136"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(bikes_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?read.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap of Bike Rentals by time and day of week\n",
    "\n",
    "A heatmap is a graphical representation of data where the individual values contained in a matrix are represented as colors. See an example here https://stanford.edu/~mwaskom/software/seaborn/examples/heatmap_annotation.html\n",
    "\n",
    "In order to do our heatmap we use the library Seaborn. It is a Python visualization library based on matplotlib. It provides a high-level interface for drawing attractive statistical graphics.\n",
    "\n",
    "Here goes the necessary imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare data as matrix\n",
    "\n",
    "In order to plot our heatmap we need to frame the data as follows:\n",
    "<pre>\n",
    "  Weekday\n",
    "|----------|-----|-----|-------|-----|-----|\n",
    "|          |  0  |  1  |  ...  |  22 |  23 | -- Hour\n",
    "|----------|-----|-----|-------|-----|-----|\n",
    "|  Monday  |  4  |  5  |  ...  |  47 | 22  |\n",
    "|  Tuesday |  6  |  9  |  ...  |  88 | 44  |\n",
    "|  ...     |  .  |  .  |  ...  |  .  |  .  |\n",
    "|  Sunday  |  0  |  2  |  ...  |  4  |  6  |\n",
    "|----------|-----|-----|-------|-----|-----|\n",
    "</pre>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivoting Data in SparkSQL\n",
    "Pivot tables are an essential part of data analysis and reporting. A pivot can be thought of as translating rows into columns while applying one or more aggregations.\n",
    "\n",
    "Here goes an example:\n",
    "<pre>\n",
    "+---+-----+---+\n",
    "|cat| type|qty|\n",
    "+---+-----+---+\n",
    "|one|small|  1|\n",
    "|one|large|  2|                  Aggregates by \"cat\" and pivots the \"type\" column then averages \"qty\".\n",
    "|one|large|  2|                  +---+-------+-----+\n",
    "|two|small|  3|                  |cat|  large|small|\n",
    "|two|small|  3|          ===>    +---+-------+-----+\n",
    "|one|large|  4|                  |two|    7.0|  4.0|\n",
    "|one|small|  5|                  |one|   2.66|  3.0|\n",
    "|two|small|  6|                  +---+-------+-----+\n",
    "|two|large|  7|\n",
    "+---+-----+---+\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>cat</th><th scope=col>type</th><th scope=col>qty</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>one  </td><td>small</td><td>1    </td></tr>\n",
       "\t<tr><th scope=row>2</th><td>one  </td><td>large</td><td>2    </td></tr>\n",
       "\t<tr><th scope=row>3</th><td>one  </td><td>large</td><td>2    </td></tr>\n",
       "\t<tr><th scope=row>4</th><td>two  </td><td>small</td><td>3    </td></tr>\n",
       "\t<tr><th scope=row>5</th><td>two  </td><td>small</td><td>3    </td></tr>\n",
       "\t<tr><th scope=row>6</th><td>one  </td><td>large</td><td>4    </td></tr>\n",
       "\t<tr><th scope=row>7</th><td>one  </td><td>small</td><td>5    </td></tr>\n",
       "\t<tr><th scope=row>8</th><td>two  </td><td>small</td><td>6    </td></tr>\n",
       "\t<tr><th scope=row>9</th><td>two  </td><td>large</td><td>7    </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       "  & cat & type & qty\\\\\n",
       "\\hline\n",
       "\t1 & one   & small & 1    \\\\\n",
       "\t2 & one   & large & 2    \\\\\n",
       "\t3 & one   & large & 2    \\\\\n",
       "\t4 & two   & small & 3    \\\\\n",
       "\t5 & two   & small & 3    \\\\\n",
       "\t6 & one   & large & 4    \\\\\n",
       "\t7 & one   & small & 5    \\\\\n",
       "\t8 & two   & small & 6    \\\\\n",
       "\t9 & two   & large & 7    \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "  cat  type qty\n",
       "1 one small   1\n",
       "2 one large   2\n",
       "3 one large   2\n",
       "4 two small   3\n",
       "5 two small   3\n",
       "6 one large   4\n",
       "7 one small   5\n",
       "8 two small   6\n",
       "9 two large   7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fake_data <- data.frame(cat = c('one', 'one', 'one', 'two', 'two', 'one', 'one', 'two', 'two'),\n",
    "                        type = c('small', 'large', 'large', 'small', 'small', 'large', 'small', 'small', 'large'),\n",
    "                        qty = c(1, 2, 2, 3, 3, 4, 5, 6, 7))\n",
    "\n",
    "df_fake <- createDataFrame(sqlContext, fake_data)\n",
    "collect(df_fake)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note__: pivot function is not yet implemented for R API, there's an issue in progress (https://github.com/apache/spark/pull/13295)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using qty as value column: use value.var to override.\n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in FUN(X[[i]], ...): envir must be either NULL, a list, or an environment.\n",
     "output_type": "error",
     "traceback": [
      "Error in FUN(X[[i]], ...): envir must be either NULL, a list, or an environment.\nTraceback:\n",
      "1. dcast(df_fake, cat ~ type, sum)",
      "2. cast(data, formula, fun.aggregate, ..., subset = subset, fill = fill, \n .     drop = drop, value.var = value.var)",
      "3. lapply(formula, eval.quoted, envir = data, enclos = parent.frame(2))",
      "4. FUN(X[[i]], ...)",
      "5. stop(\"envir must be either NULL, a list, or an environment.\")"
     ]
    }
   ],
   "source": [
    "library(reshape2)\n",
    "dcast(df_fake, cat ~ type, sum)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
